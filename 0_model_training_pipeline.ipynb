{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker model training & tuning pipeline\n",
    "\n",
    "***This notebook works best with the `Data Science 3.0` kernel on an `ml.t3.medium` instance type***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customers can use SageMaker Pipelines to build scalable machine learning pipelines that pre-process data and train machine learning models. With SageMaker Pipelines, customers have a toolkit for every part of the machine learning lifecycle that provides deep customizations and tuning options to fit every organization. Customers have the freedom to customize SageMaker Pipelines to specific use cases, but also to create generic machine learning pipelines that can be reused across different use cases.\n",
    "\n",
    "From a birds-eye view a machine learning pipeline usually consists of 3 general steps: a pre-process step where the data is transformed, a training step where a machine learning model is trained, and an evaluation step which tests the performance of the trained model. If the model is performing according to the objective metric youâ€™re optimizing for, then that becomes a candidate model for deployment to one or more environments. These candidate models should be registered into SageMaker Model Registry to catalog and store key metadata for that model version.\n",
    "\n",
    "--- \n",
    "\n",
    "These steps have a lot of commonalities, even across different machine learning use cases. Customers that want to create training pipelines that can be re-used in an organization can use SageMaker Pipelines to create parameterized, generic training pipelines. Parameters allow customers to identify specific parameters that can be passed into the pipeline during pipeline execution without having to directly change the pipeline code itself. \n",
    "\n",
    "**This notebook** demonstrates how SageMaker Pipelines can be used to string together a sequence of data processing, model training, tuning and evaluation step to train a binary classification machine learning model using [`scikit-learn`](https://pypi.org/project/scikit-learn/). The trained model can then be used for batch inference, see [`1_batch_transform_pipeline`](./1_batch_transform_pipeline.ipynb) or hosted on a SageMaker endpoint for realtime inference, see [`2_realtime_inference`](./2_realtime_inference.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Pipelines\n",
    "Amazon SageMaker Pipelines is a purpose-built, easy-to-use CI/CD service for machine learning. With SageMaker Pipelines, customers can create machine learning workflows with an easy-to-use Python SDK, and then visualize and manage workflows using Amazon SageMaker Studio.\n",
    "\n",
    "\n",
    "#### SageMaker Pipeline steps and parameters\n",
    "SageMaker pipelines works on the concept of steps. The order steps are executed in is inferred from the dependencies each step has. If a step has a dependency on the output from a previous step, it's not executed until after that step has completed successfully.\n",
    "\n",
    "SageMaker Pipeline Parameters are input parameters specified when triggering a pipeline execution. They need to be explicitly defined when creating the pipeline and contain default values.\n",
    "(https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html).\n",
    "\n",
    "#### SageMaker Pipeline DAG\n",
    "\n",
    "When creating a SageMaker Pipeline, SageMaker creates a Direct Acyclic Graph, DAG, that customers can visualize in Amazon SageMaker Studio. The DAG can be used to track pipeline executions, outputs and metrics. In this notebook, a SageMaker Pipeline with the following DAG is created:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict customer orders with Random Forest Classifier\n",
    "\n",
    "### Data\n",
    "\n",
    "This notebook uses PrestoDB to extract `tpc-h` data from the `tpc-h connector`, and includes the data extraction, pre-procesing, as well as the splitting of data into train, test, and validation databases as a part of the preprocessing step of this sagemaker pipeline. \n",
    "\n",
    "***To configure PrestoDB within your EC2 instance view***: see instructions in the [README](./README.md) file.\n",
    "\n",
    "\n",
    "### Overview \n",
    "\n",
    "This model is a binary classification model creating using the scikit-learn `RandomForestClassifier`. It categorizes input data into high value/low value order classes. \n",
    "\n",
    "Training data: the training data for this model is available via PrestoDB tables and is read into Pandas through the PrestoDB Python client. This data is then read into an Apache Spark dataframe (although the model training happens only using the data in the Pandas dataframe).\n",
    "\n",
    "* Data is read using queries from PrestoDB and any feature engineering required is done as part of the query itself.\n",
    "\n",
    "* Note that ingestion of raw data into PrestoDB tables is outside the scope of this project and it is assumed that for the purpose of model training the data can simply be queried from PrestoDB tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sagemaker==2.208.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.208.0)\n",
      "Requirement already satisfied: presto-python-client==0.8.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.8.4)\n",
      "Requirement already satisfied: scikit-learn==1.4.1.post1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.4.1.post1)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (1.34.82)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (6.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (2.1.4)\n",
      "Requirement already satisfied: pathos in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (0.3.2)\n",
      "Requirement already satisfied: schema in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (4.19.2)\n",
      "Requirement already satisfied: platformdirs in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: tblib<3,>=1.7.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: requests in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: docker in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sagemaker==2.208.0->-r requirements.txt (line 1)) (5.9.0)\n",
      "Requirement already satisfied: click in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from presto-python-client==0.8.4->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: six in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from presto-python-client==0.8.4->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 3)) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.82 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.208.0->-r requirements.txt (line 1)) (1.34.82)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.208.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.208.0->-r requirements.txt (line 1)) (0.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.208.0->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from requests->sagemaker==2.208.0->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from requests->sagemaker==2.208.0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from requests->sagemaker==2.208.0->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from jsonschema->sagemaker==2.208.0->-r requirements.txt (line 1)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from jsonschema->sagemaker==2.208.0->-r requirements.txt (line 1)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from jsonschema->sagemaker==2.208.0->-r requirements.txt (line 1)) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas->sagemaker==2.208.0->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas->sagemaker==2.208.0->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas->sagemaker==2.208.0->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pathos->sagemaker==2.208.0->-r requirements.txt (line 1)) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pathos->sagemaker==2.208.0->-r requirements.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pathos->sagemaker==2.208.0->-r requirements.txt (line 1)) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pathos->sagemaker==2.208.0->-r requirements.txt (line 1)) (0.70.16)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from schema->sagemaker==2.208.0->-r requirements.txt (line 1)) (21.6.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt  --upgrade-strategy only-if-needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/madhurpt/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "## Install the necessary boto3 and sagemaker libraries to initialize session\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "import logging\n",
    "import sagemaker\n",
    "from glob import glob\n",
    "import sagemaker.session\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from datetime import datetime\n",
    "from utils import (load_config,\n",
    "                    print_pipeline_execution_summary)\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, CategoricalParameter\n",
    "\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set the logger to track all of the logs as this pipeline runs\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Config.yml file that contains information that is used across this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:10,370] p60565 {2294058105.py:2} INFO - {\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"sagemaker_execution_role_name\": \"service-role/AmazonSageMaker-ExecutionRole-20220504T122644\",\n",
      "    \"sagemaker_execution_role_arn\": \"arn:aws:iam::{account_id}:role/{role}\",\n",
      "    \"s3_bucket\": \"sagemaker-{region}-{account_id}\",\n",
      "    \"s3_prefix\": \"mlops-pipeline\",\n",
      "    \"network_config\": {\n",
      "      \"enable_network_isolation\": false,\n",
      "      \"security_group_ids\": null,\n",
      "      \"subnets\": null\n",
      "    }\n",
      "  },\n",
      "  \"presto\": {\n",
      "    \"host\": \"54.236.14.197\",\n",
      "    \"parameter\": \"8080\",\n",
      "    \"presto_credentials\": \"presto-credentials\",\n",
      "    \"catalog\": \"tpch\",\n",
      "    \"schema\": \"tiny\"\n",
      "  },\n",
      "  \"pipeline\": {\n",
      "    \"training_pipeline_name\": \"mlops-training-pipeline\",\n",
      "    \"transform_pipeline_name\": \"mlops-transform-pipeline\",\n",
      "    \"base_job_name\": \"mlops-pipeline\",\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"training_step\": {\n",
      "    \"training_target\": \"high_value_order\",\n",
      "    \"training_features\": [\n",
      "      \"total_extended_price\",\n",
      "      \"avg_discount\",\n",
      "      \"total_quantity\"\n",
      "    ],\n",
      "    \"sklearn_framework_version\": \"0.23-1\",\n",
      "    \"n_estimators\": 75,\n",
      "    \"max_depth\": 10,\n",
      "    \"min_samples_split\": 2,\n",
      "    \"max_features\": \"sqrt\",\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"base_job_name\": \"rf-sklearn\",\n",
      "    \"train_split\": 0.7,\n",
      "    \"test_split\": 0.9,\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ],\n",
      "    \"query\": \"SELECT\\n    o.orderkey,\\n    COUNT(l.linenumber) AS lineitem_count,\\n    SUM(l.quantity) AS total_quantity,\\n    AVG(l.discount) AS avg_discount,\\n    SUM(l.extendedprice) AS total_extended_price,\\n    SUM(l.tax) AS total_payable_tax,\\n    o.orderdate,\\n    o.orderpriority,\\n    CASE\\n        WHEN (o.orderpriority = '2-HIGH') THEN 1\\n        ELSE 0\\n    END AS high_value_order\\nFROM\\n    orders o\\nJOIN\\n    lineitem l ON o.orderkey = l.orderkey\\nGROUP BY\\n    o.orderkey,\\n    o.orderdate,\\n    o.orderpriority\\nORDER BY \\n    RANDOM() \\nLIMIT 5000\\n\"\n",
      "  },\n",
      "  \"tuning_step\": {\n",
      "    \"step_name\": \"Train-And-Tune-Model\",\n",
      "    \"maximum_parallel_training_jobs\": 1,\n",
      "    \"maximum_training_jobs\": 2,\n",
      "    \"hyperparam_ranges\": {\n",
      "      \"n_estimators\": [\n",
      "        10,\n",
      "        150\n",
      "      ],\n",
      "      \"max_depth\": [\n",
      "        3,\n",
      "        20\n",
      "      ],\n",
      "      \"min_samples_split\": [\n",
      "        2,\n",
      "        10\n",
      "      ],\n",
      "      \"max_features\": [\n",
      "        \"sqrt\",\n",
      "        \"log2\"\n",
      "      ]\n",
      "    },\n",
      "    \"metric_definitions\": [\n",
      "      {\n",
      "        \"Name\": \"validation:auc\",\n",
      "        \"Regex\": \"auc (\\\\S+)\"\n",
      "      }\n",
      "    ],\n",
      "    \"objective_metric_name\": \"validation:auc\"\n",
      "  },\n",
      "  \"evaluation_step\": {\n",
      "    \"step_name\": \"Evaluate-Model\",\n",
      "    \"accuracy_condition_threshold\": 0.62,\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"evaluation_filename\": \"evaluation.json\"\n",
      "  },\n",
      "  \"transform_step\": {\n",
      "    \"step_name\": \"mlops-RandomForestTransform\",\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"num_hours_to_go_back\": 1,\n",
      "    \"output_prefix\": \"batch_transform_output\",\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ],\n",
      "    \"query\": \"SELECT\\n    o.orderkey,\\n    COUNT(l.linenumber) AS lineitem_count,\\n    SUM(l.quantity) AS total_quantity,\\n    AVG(l.discount) AS avg_discount,\\n    SUM(l.extendedprice) AS total_extended_price,\\n    SUM(l.tax) AS total_payable_tax,\\n    o.orderdate,\\n    o.orderpriority,\\n    CASE\\n        WHEN (o.orderpriority = '2-HIGH') THEN 1\\n        ELSE 0\\n    END AS high_value_order\\nFROM\\n    orders o\\nJOIN\\n    lineitem l ON o.orderkey = l.orderkey\\nGROUP BY\\n    o.orderkey,\\n    o.orderdate,\\n    o.orderpriority\\nORDER BY \\n    RANDOM() \\nLIMIT 5000\\n\"\n",
      "  },\n",
      "  \"data_processing_step\": {\n",
      "    \"step_name\": \"Preprocess-Data\",\n",
      "    \"processing_instance_type\": \"ml.c5.xlarge\",\n",
      "    \"instance_count\": 1,\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"register_model_step\": {\n",
      "    \"step_name\": \"Register-Model\",\n",
      "    \"model_group\": \"mlops-model\",\n",
      "    \"model_name\": \"mlops-model\",\n",
      "    \"approval_status\": \"PendingManualApproval\",\n",
      "    \"inference_instance_types\": [\n",
      "      \"ml.t2.medium\",\n",
      "      \"ml.m5.xlarge\",\n",
      "      \"ml.m5.large\"\n",
      "    ],\n",
      "    \"transform_instance_types\": [\n",
      "      \"ml.m5.xlarge\"\n",
      "    ],\n",
      "    \"tags\": [\n",
      "      {\n",
      "        \"Key\": \"team\",\n",
      "        \"Value\": \"my-team\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"fail_step\": {\n",
      "    \"step_name\": \"AccuracyThresholdFailed\"\n",
      "  },\n",
      "  \"condition_step\": {\n",
      "    \"step_name\": \"Accuracy-Condition\"\n",
      "  },\n",
      "  \"realtime_endpoint\": {\n",
      "    \"endpoint_config_name\": \"random-forest-classifier\",\n",
      "    \"endpoint_name\": \"mlops-realtime-ep\",\n",
      "    \"instance_type\": \"ml.m5.xlarge\",\n",
      "    \"min_instance_count\": 1,\n",
      "    \"max_instance_count\": 3\n",
      "  },\n",
      "  \"scripts\": {\n",
      "    \"source_dir\": \"code\",\n",
      "    \"query\": \"query.py\",\n",
      "    \"preprocess_data\": \"presto_preprocess_for_training.py\",\n",
      "    \"evaluation\": \"code/evaluate.py\",\n",
      "    \"batch_transform_get_data\": \"presto_preprocess_for_batch_inference.py\",\n",
      "    \"batch_inference\": \"code/inference.py\",\n",
      "    \"training_script\": \"code/training.py\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config = load_config('config.yml')\n",
    "logger.info(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:10,380] p60565 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/query.py sagemaker-us-east-1-015469603702 mlops-pipeline/code/query.py\n",
      "code/presto_preprocess_for_training.py sagemaker-us-east-1-015469603702 mlops-pipeline/code/presto_preprocess_for_training.py\n",
      "code/presto_preprocess_for_batch_inference.py sagemaker-us-east-1-015469603702 mlops-pipeline/code/presto_preprocess_for_batch_inference.py\n",
      "code/presto_utils.py sagemaker-us-east-1-015469603702 mlops-pipeline/code/presto_utils.py\n",
      "code/inference.py sagemaker-us-east-1-015469603702 mlops-pipeline/code/inference.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:11,694] p60565 {2739517910.py:22} INFO - bucket=sagemaker-us-east-1-015469603702, prefix=mlops-pipeline, role=arn:aws:iam::015469603702:role/service-role/AmazonSageMaker-ExecutionRole-20220504T122644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/evaluate.py sagemaker-us-east-1-015469603702 mlops-pipeline/code/evaluate.py\n",
      "code/training.py sagemaker-us-east-1-015469603702 mlops-pipeline/code/training.py\n",
      "code/requirements.txt sagemaker-us-east-1-015469603702 mlops-pipeline/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "## initialize the sagemaker session, region, role bucket and pipeline session\n",
    "s3 = boto3.client('s3')\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "ci = boto3.client('sts').get_caller_identity()\n",
    "bucket = config['aws']['s3_bucket'].format(account_id=ci['Account'], region=region)\n",
    "pipeline_session = PipelineSession(default_bucket=bucket)\n",
    "\n",
    "source_dir = config['scripts']['source_dir']\n",
    "role_name = config['aws']['sagemaker_execution_role_name']\n",
    "config['aws']['sagemaker_execution_role_arn'] = config['aws']['sagemaker_execution_role_arn'].format(account_id=ci['Account'], role=role_name)\n",
    "role = config['aws']['sagemaker_execution_role_arn']\n",
    "\n",
    "prefix = config['aws']['s3_prefix']  # Prefix to S3 artifacts\n",
    "\n",
    "files = glob(os.path.join(source_dir, \"*.py\")) + glob(os.path.join(source_dir, \"*.txt\"))\n",
    "\n",
    "for file in files:\n",
    "    s3.upload_file(file, bucket, f\"{prefix}/{file}\")\n",
    "    print(file, bucket, f\"{prefix}/{file}\")\n",
    "\n",
    "logger.info(f\"bucket={bucket}, prefix={prefix}, role={role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters that are used throughout the training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:11,711] p60565 {1030891492.py:3} INFO - the training features being used for this pipeline --> [\"total_extended_price\", \"avg_discount\", \"total_quantity\"]\n",
      "[2024-04-11 20:21:11,713] p60565 {1030891492.py:25} INFO - writing training query to code/query.py\n"
     ]
    }
   ],
   "source": [
    "# Convert your list to a JSON string\n",
    "training_features_str = json.dumps(config['training_step']['training_features'])\n",
    "logger.info(f\"the training features being used for this pipeline --> {training_features_str}\")\n",
    "\n",
    "# Define new pipeline parameters\n",
    "host_parameter = ParameterString(name=\"HostParameter\", default_value=config['presto']['host'])\n",
    "port_parameter = ParameterString(name=\"PortParameter\", default_value=config['presto']['parameter'])\n",
    "target_parameter = ParameterString(name=\"Target\", default_value=config['training_step']['training_target'])\n",
    "feature_parameter = ParameterString(name=\"Feature\", default_value=training_features_str)\n",
    "\n",
    "## presto credential key and region pipeline parameters\n",
    "presto_parameter = ParameterString(name=\"PrestoParameter\", default_value=config['presto']['presto_credentials'])\n",
    "region_parameter = ParameterString(name=\"Region\", default_value=config['aws']['region'])\n",
    "\n",
    "## represents the parameters being used to track the catalog and the schema needed to connect to the presto server\n",
    "presto_catalog_parameter = ParameterString(name=\"Catalog\", default_value=config['presto']['catalog'])\n",
    "presto_schema_parameter = ParameterString(name=\"Schema\", default_value=config['presto']['schema'])\n",
    "\n",
    "## represents the parameters being used to track train test split calculation\n",
    "train_split = ParameterFloat(name=\"TrainSplit\", default_value=config['training_step']['train_split'])\n",
    "test_split = ParameterFloat(name=\"TestSplit\", default_value=config['training_step']['test_split'])\n",
    "\n",
    "# query for the training job, write it to query_training.py\n",
    "fpath: str = os.path.join(config['scripts']['source_dir'], config['scripts']['query'])\n",
    "logger.info(f\"writing training query to {fpath}\")\n",
    "\n",
    "Path(fpath).write_text(f\"TRAINING_DATA_QUERY=\\\"\\\"\\\"{config['training_step']['query']}\\\"\\\"\\\"\")\n",
    "\n",
    "\n",
    "# approval status for trained model\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=config['register_model_step']['approval_status']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameters'></a>\n",
    "\n",
    "### Pipeline input parameters\n",
    "\n",
    "Pipeline Parameters are input parameter when triggering a pipeline execution. They need to be explicitly defined when creating the pipeline and contain default values.\n",
    "\n",
    "Create parameters for the inputs to the pipeline. In this case, parameters will be used for:\n",
    "- `ModelGroup` - Which registry to register the trained model with.\n",
    "- `InputData` - S3 URI to pipeline input data.\n",
    "- `PreprocessScript` - S3 URI to python script to pre-process the data.\n",
    "- `EvaluateScript` - S3 URI to python script to evaluate the trained model.\n",
    "- `MaximumTrainingJobs` - How many training jobs to allow when hyperparameter tuning the model\n",
    "- `MaximumParallelTrainingJobs` - How many training jobs to allow in parallel when hyperparameter tuning the model.\n",
    "- `AccuracyConditionThreshold` - Only register models with the model registry if the have at least this classification accuracy.\n",
    "- `ProcessingInstanceType` - What EC2 instance type to use for processing.\n",
    "- `TrainingInstanceType` - What EC2 instance type to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To what Registry to register the model and its versions.\n",
    "model_group = ParameterString(name=\"ModelGroup\", default_value=config['register_model_step']['model_group'])\n",
    "\n",
    "# Maximum amount of training jobs to allow in the HP tuning\n",
    "max_training_jobs = ParameterInteger(name=\"MaximumTrainingJobs\", default_value=config['tuning_step']['maximum_training_jobs'])\n",
    "\n",
    "# Maximum amount of training jobs to allow in the HP tuning\n",
    "max_parallel_training_jobs = ParameterInteger(name=\"MaximumParallelTrainingJobs\", default_value=config['tuning_step']['maximum_parallel_training_jobs'])\n",
    "\n",
    "# Accuracy threshold to decide whether or not to register the model with Model Registry\n",
    "accuracy_condition_threshold = ParameterFloat(name=\"AccuracyConditionThreshold\", default_value=config['evaluation_step']['accuracy_condition_threshold'])\n",
    "\n",
    "# What instance type to use for processing.\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=config['data_processing_step']['processing_instance_type']\n",
    ")\n",
    "\n",
    "# What instance type to use for training.\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=config['training_step']['instance_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocess'></a>\n",
    "\n",
    "## Preprocess data step\n",
    "--- \n",
    "In the first step an sklearn processor is created, used in the ProcessingStep. In this step, the preprocess script is read to connect to presto and query data, that is then sent to an Amazon S3 bucket split into train, test and validation datasets. Using these files, this step can then use the data for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:11,732] p60565 {estimator.py:294} WARNING - instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "[2024-04-11 20:21:11,737] p60565 {utilities.py:422} WARNING - The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "[2024-04-11 20:21:11,749] p60565 {utilities.py:422} WARNING - The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create SKlearn processor object,\n",
    "# The object contains information about what instance type to use, the IAM role to use etc.\n",
    "# A managed processor comes with a pre configured container, so only specifying version is required.\n",
    "est_cls = sagemaker.sklearn.estimator.SKLearn\n",
    "\n",
    "nw_cfg = config['aws']['network_config']\n",
    "\n",
    "network_config = sagemaker.network.NetworkConfig(\n",
    "    enable_network_isolation=nw_cfg['enable_network_isolation'],\n",
    "    security_group_ids=nw_cfg['security_group_ids'], \n",
    "    subnets=nw_cfg['subnets']\n",
    ")\n",
    "\n",
    "sklearn_processor = FrameworkProcessor(\n",
    "                                     estimator_cls=est_cls,\n",
    "                                     framework_version=config['training_step']['sklearn_framework_version'],\n",
    "                                     role=role,\n",
    "                                     instance_type=processing_instance_type,\n",
    "                                     instance_count=config['data_processing_step']['instance_count'],\n",
    "                                     tags=config['data_processing_step']['tags'], \n",
    "                                     sagemaker_session=pipeline_session,\n",
    "                                     base_job_name=config['pipeline']['base_job_name'], \n",
    "                                     network_config=network_config\n",
    ")\n",
    "\n",
    "outputs_preprocessor = [\n",
    "    ProcessingOutput(\n",
    "        output_name=\"train\",\n",
    "        source=\"/opt/ml/processing/train\",\n",
    "        destination=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                \"s3://{}\".format(bucket),\n",
    "                prefix,\n",
    "                ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                \"train\",\n",
    "            ],\n",
    "        ),\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"validation\",\n",
    "        source=\"/opt/ml/processing/validation\",\n",
    "        destination=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                \"s3://{}\".format(bucket),\n",
    "                prefix,\n",
    "                ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                \"validation\",\n",
    "            ],\n",
    "        ),\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"test\",\n",
    "        source=\"/opt/ml/processing/test\",\n",
    "        destination=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                \"s3://{}\".format(bucket),\n",
    "                prefix,\n",
    "                ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                \"test\",\n",
    "            ],\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# Use the sklearn_processor in a SageMaker Pipelines ProcessingStep\n",
    "# Configure the ProcessingStep\n",
    "# Use the sklearn_processor's run method and configure the ProcessingStep\n",
    "step_args = sklearn_processor.run(\n",
    "    code=config['scripts']['preprocess_data'],\n",
    "    source_dir=config['scripts']['source_dir'], \n",
    "    outputs=outputs_preprocessor,\n",
    "    arguments=[\n",
    "        \"--host\", host_parameter,\n",
    "        \"--port\", port_parameter,\n",
    "        \"--presto_credentials_key\", presto_parameter,\n",
    "        \"--region\", region_parameter,\n",
    "        \"--presto_catalog\", presto_catalog_parameter,\n",
    "        \"--presto_schema\", presto_schema_parameter,\n",
    "        \"--train_split\", train_split.to_string(), \n",
    "        \"--test_split\", test_split.to_string(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "step_preprocess_data = ProcessingStep(\n",
    "    name=config['data_processing_step']['step_name'],\n",
    "    step_args=step_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train'></a>\n",
    "\n",
    "## Train model step\n",
    "In the second step, the train and validation output from the previous processing step are used to train a model. \n",
    "\n",
    "---\n",
    "\n",
    "We use the SKLearn estimator from SageMaker SDK and the RandomForestClassifier from scikit-learn to train the ML model. The HyperparameterTunerclass is used for running automatic model tuning to determine the set of hyperparameters that provide the best performance (maximize the AUC metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:11,767] p60565 {2361537882.py:9} INFO - training step image_uri=683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "# Fetch container to use for training\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=config['training_step']['sklearn_framework_version'],\n",
    "    py_version=\"py3\",\n",
    "    instance_type=config['training_step']['instance_type'],\n",
    ")\n",
    "logger.info(f\"training step image_uri={image_uri}\")\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=config['scripts']['training_script'],\n",
    "    role=role,\n",
    "    instance_count=config['training_step']['instance_count'],\n",
    "    instance_type=config['training_step']['instance_type'],\n",
    "    framework_version=config['training_step']['sklearn_framework_version'],\n",
    "    base_job_name=config['training_step']['base_job_name'],\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": config['training_step']['n_estimators'],\n",
    "        \"max_depth\": config['training_step']['max_depth'],  \n",
    "        \"features\": config['training_step']['training_features'],\n",
    "        \"target\": config['training_step']['training_target'],\n",
    "    },\n",
    "    tags=config['training_step']['tags'],\n",
    "    # output_path=f\"s3://{bucket}/{prefix}\", # removing this since the model.tar.gz file is not found by the evaluation step once it is sent to this output path for some reason\n",
    ")\n",
    "\n",
    "# Create Hyperparameter tuner object. Ranges from https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html\n",
    "rf_tuner = HyperparameterTuner(\n",
    "                estimator=sklearn_estimator,\n",
    "                objective_metric_name=config['tuning_step']['objective_metric_name'],\n",
    "                hyperparameter_ranges={\n",
    "                    \"n_estimators\": IntegerParameter(config['tuning_step']['hyperparam_ranges']['n_estimators'][0], config['tuning_step']['hyperparam_ranges']['n_estimators'][1]),\n",
    "                    \"max_depth\": IntegerParameter(config['tuning_step']['hyperparam_ranges']['max_depth'][0], config['tuning_step']['hyperparam_ranges']['max_depth'][1]),\n",
    "                    \"min_samples_split\": IntegerParameter(config['tuning_step']['hyperparam_ranges']['min_samples_split'][0], config['tuning_step']['hyperparam_ranges']['min_samples_split'][1]),\n",
    "                    \"max_features\": CategoricalParameter(config['tuning_step']['hyperparam_ranges']['max_features'])\n",
    "                },\n",
    "                max_jobs=config['tuning_step']['maximum_training_jobs'], ## reducing this for testing purposes\n",
    "                metric_definitions=config['tuning_step']['metric_definitions'],\n",
    "                max_parallel_jobs=config['tuning_step']['maximum_parallel_training_jobs'], ## reducing this for testing purposes\n",
    ")\n",
    "\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name=config['tuning_step']['step_name'],\n",
    "    tuner=rf_tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\" \n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "        s3_data=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model step\n",
    "---\n",
    "\n",
    "When a model is trained, it's common to evaluate the model on unseen data before registering it with the model registry. This ensures the model registry isn't cluttered with poorly performing model versions. The purpose of the model evaluation step is to check that the trained and tuned model has an accuracy level above a configurable threshold and only then register the model with the model registry (from where it can be subsequently approved and deployed). If the model accuracy does not meet a configured threshold then the pipeline fails and the model is not registered with the model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create ScriptProcessor object.\n",
    "# The object contains information about what container to use, what instance type etc.\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=config['evaluation_step']['instance_type'],\n",
    "    instance_count=config['evaluation_step']['instance_count'],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Create a PropertyFile\n",
    "# A PropertyFile is used to be able to reference outputs from a processing step, for instance to use in a condition step.\n",
    "# For more information, visit https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=config['evaluation_step']['evaluation_filename']\n",
    ")\n",
    "\n",
    "\n",
    "step_evaluate_model = ProcessingStep(\n",
    "    name=config['evaluation_step']['step_name'],\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=bucket),\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "            input_name=\"model.tar.gz\" \n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "            input_name=\"test.csv\" \n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"evaluation\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code = f\"s3://{bucket}/{prefix}/{config['scripts']['evaluation']}\",\n",
    "    property_files=[evaluation_report],\n",
    "    job_arguments=[\n",
    "        \"--target\", target_parameter,\n",
    "        \"--features\", feature_parameter,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='register'></a>\n",
    "\n",
    "## Register model step\n",
    "If the trained model meets the model performance requirements, a new model version is registered with the model registry for further analysis. To attach model metrics to the model version, create a [ModelMetrics](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html) object using the evaluation report created in the evaluation step. Then, create the RegisterModel step.\n",
    "\n",
    "The model is registered with the model Registry with approval status set to PendingManualApproval, this means the model cannot be deployed on a SageMaker Endpoint unless its status in the registry is changed to Approved manually via the SageMaker console, programmatically or through a Lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:11,875] p60565 {utilities.py:465} WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "# Create ModelMetrics object using the evaluation report from the evaluation step\n",
    "# A ModelMetrics object contains metrics captured from a model.\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                step_evaluate_model.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\n",
    "                    \"S3Uri\"\n",
    "                ],\n",
    "                config['evaluation_step']['evaluation_filename'],\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Crete a RegisterModel step, which registers the model with SageMaker Model Registry.\n",
    "step_register_model = RegisterModel(\n",
    "    name=config['register_model_step']['step_name'],\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=bucket),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=config['register_model_step']['inference_instance_types'],\n",
    "    transform_instances=config['register_model_step']['transform_instance_types'],\n",
    "    model_package_group_name=model_group,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    "    tags=config['register_model_step']['tags']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='condition'></a>\n",
    "\n",
    "## Accuracy condition step\n",
    "Adding conditions to the pipeline is done with a ConditionStep.\n",
    "In this case, we only want to register the new model version with the model registry if the new model meets an accuracy condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_fail = FailStep(\n",
    "    name=config['fail_step']['step_name'],\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to Accuracy <\", accuracy_condition_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create accuracy condition to ensure the model meets performance requirements.\n",
    "# Models with a test accuracy lower than the condition will not be registered with the model registry.\n",
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate_model.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.accuracy.value\",\n",
    "    ),\n",
    "    right=accuracy_condition_threshold,\n",
    ")\n",
    "\n",
    "# Create a SageMaker Pipelines ConditionStep, using the condition above.\n",
    "# Enter the steps to perform if the condition returns True / False.\n",
    "step_cond = ConditionStep(\n",
    "    name=config['condition_step']['step_name'],\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_register_model],\n",
    "    else_steps=[step_fail], ## if this fails - add a step here (from the quip)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='orchestrate'></a>\n",
    "\n",
    "## Pipeline Creation: Orchestrate all steps\n",
    "\n",
    "Now that all pipeline steps are created, a pipeline is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a SageMaker Pipeline.\n",
    "# Each parameter for the pipeline must be set as a parameter explicitly when the pipeline is created.\n",
    "# Also pass in each of the steps created above.\n",
    "# Note that the order of execution is determined from each step's dependencies on other steps,\n",
    "# not on the order they are passed in below.\n",
    "pipeline = Pipeline(\n",
    "    name=config['pipeline']['training_pipeline_name'],\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        accuracy_condition_threshold,\n",
    "        model_group,\n",
    "        max_parallel_training_jobs,\n",
    "        max_training_jobs,\n",
    "        host_parameter,\n",
    "        region_parameter,\n",
    "        presto_parameter,\n",
    "        port_parameter,\n",
    "        target_parameter, \n",
    "        feature_parameter,\n",
    "        model_approval_status,\n",
    "        presto_catalog_parameter,\n",
    "        presto_schema_parameter,\n",
    "        train_split, \n",
    "        test_split,\n",
    "    ],\n",
    "    steps=[\n",
    "            step_preprocess_data, \n",
    "            step_tuning, \n",
    "            step_evaluate_model, \n",
    "            step_cond\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:11,905] p60565 {estimator.py:294} WARNING - instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "[2024-04-11 20:21:12,394] p60565 {processing.py:1884} INFO - Uploaded code to s3://sagemaker-us-east-1-015469603702/mlops-training-pipeline/code/3d32151c6b1036a85990517a57937f11/sourcedir.tar.gz\n",
      "[2024-04-11 20:21:12,485] p60565 {processing.py:1976} INFO - runproc.sh uploaded to s3://sagemaker-us-east-1-015469603702/mlops-training-pipeline/code/0c7a09692b1907b6f72a698c10f53598/runproc.sh\n",
      "[2024-04-11 20:21:12,485] p60565 {utilities.py:465} WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-04-11 20:21:13,396] p60565 {estimator.py:1846} WARNING - No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "[2024-04-11 20:21:13,396] p60565 {estimator.py:1846} WARNING - No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "[2024-04-11 20:21:13,397] p60565 {utilities.py:465} WARNING - Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-04-11 20:21:13,398] p60565 {utilities.py:465} WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-04-11 20:21:13,398] p60565 {estimator.py:1846} WARNING - No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "[2024-04-11 20:21:13,399] p60565 {_utils.py:497} WARNING - Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "[2024-04-11 20:21:13,399] p60565 {utilities.py:465} WARNING - Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-04-11 20:21:14,000] p60565 {estimator.py:294} WARNING - instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "[2024-04-11 20:21:14,149] p60565 {processing.py:1884} INFO - Uploaded code to s3://sagemaker-us-east-1-015469603702/mlops-training-pipeline/code/3d32151c6b1036a85990517a57937f11/sourcedir.tar.gz\n",
      "[2024-04-11 20:21:14,242] p60565 {processing.py:1976} INFO - runproc.sh uploaded to s3://sagemaker-us-east-1-015469603702/mlops-training-pipeline/code/0c7a09692b1907b6f72a698c10f53598/runproc.sh\n",
      "[2024-04-11 20:21:14,243] p60565 {utilities.py:465} WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-04-11 20:21:14,402] p60565 {estimator.py:1846} WARNING - No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "[2024-04-11 20:21:14,403] p60565 {estimator.py:1846} WARNING - No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "[2024-04-11 20:21:14,405] p60565 {utilities.py:465} WARNING - Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-04-11 20:21:14,405] p60565 {utilities.py:465} WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "[2024-04-11 20:21:14,406] p60565 {estimator.py:1846} WARNING - No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "[2024-04-11 20:21:14,406] p60565 {_utils.py:497} WARNING - Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "[2024-04-11 20:21:14,406] p60565 {utilities.py:465} WARNING - Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:015469603702:pipeline/mlops-training-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'f57a69a8-9566-4f11-8ce7-a887c108637e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f57a69a8-9566-4f11-8ce7-a887c108637e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '91',\n",
       "   'date': 'Fri, 12 Apr 2024 00:21:15 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit pipeline\n",
    "pipeline_upsert_tags = config['pipeline']['tags']\n",
    "pipeline.upsert(role_arn=role, tags=pipeline_upsert_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start pipeline with different parameters.\n",
    "Now that the pipeline is created, it can be started with custom parameters making the pipeline agnostic to who is triggering it, but also to the scripts and data used. The pipeline can be started using the CLI, the SageMaker Studio UI or the SDK and below there is a screenshot of what it looks like in the SageMaker Studio UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting the pipeline with the SDK\n",
    "In the examples below, the pipeline is triggered for two machine learning problems, each with different preprocessing scripts and model registry. Each machine learning problem is run with two different sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start pipeline with credit data and preprocessing script\n",
    "execution = pipeline.start(\n",
    "                execution_display_name=pipeline.name,\n",
    "                parameters=dict(\n",
    "                AccuracyConditionThreshold=config['evaluation_step']['accuracy_condition_threshold'],\n",
    "                MaximumParallelTrainingJobs=config['tuning_step']['maximum_parallel_training_jobs'],\n",
    "                MaximumTrainingJobs=config['tuning_step']['maximum_training_jobs'],\n",
    "                ModelGroup=config['register_model_step']['model_group'],\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:015469603702:pipeline/mlops-training-pipeline',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:015469603702:pipeline/mlops-training-pipeline/execution/ye8lxsgtwns2',\n",
       " 'PipelineExecutionDisplayName': 'mlops-training-pipeline',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2024, 4, 11, 20, 21, 15, 536000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 4, 11, 20, 21, 15, 536000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'IamIdentity': {'Arn': 'arn:aws:iam::015469603702:user/madhurpt',\n",
       "   'PrincipalId': 'AIDAQHGQPNN3OCE6QHZM5'}},\n",
       " 'LastModifiedBy': {'IamIdentity': {'Arn': 'arn:aws:iam::015469603702:user/madhurpt',\n",
       "   'PrincipalId': 'AIDAQHGQPNN3OCE6QHZM5'}},\n",
       " 'ResponseMetadata': {'RequestId': 'ba77ee41-2522-4dbf-80e8-8eb4ecbefe52',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ba77ee41-2522-4dbf-80e8-8eb4ecbefe52',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '613',\n",
       "   'date': 'Fri, 12 Apr 2024 00:21:15 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 20:21:15,819] p60565 {661491485.py:2} INFO - starting pipeline=mlops-training-pipeline\n"
     ]
    }
   ],
   "source": [
    "st = time.perf_counter()\n",
    "logger.info(f\"starting pipeline={pipeline.name}\")\n",
    "execution.wait()\n",
    "elapsed_time = time.perf_counter() - st\n",
    "logger.info(f\"pipeline={pipeline.name} took {elapsed_time:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pipeline_execution_summary(execution.list_steps(), pipeline.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that the model is registered, get access to the registered model manually on the sagemaker studio model registry console, or programmatically in the next notebook, approve it and run the second portion of this solution: Batch Transform Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
